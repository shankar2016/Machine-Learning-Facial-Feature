{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Facial Keypoint Detection\n",
    "## Chandler McCann, Christopher Miller, Rohit Nair, Natarajan Shankar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is the baseline for facial keypoint detection which is heavily borrowed from Daniel Nouri's excellent [tutorial](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/) which is a great starting point where to start our explorations.\n",
    "\n",
    "_____\n",
    "\n",
    "[Remove before submission]\n",
    "\n",
    "Project setup is as below\n",
    "\n",
    "    w207-final-project       -- base directory\n",
    "        data                    -- data folder which contains the training and test data\n",
    "        final_project.ipynb     -- python script\n",
    "\n",
    "\n",
    "Moved the data outside so tht we can keep that and other artefacts that we don't want to commit outside of repo.I,I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading required packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting tips for why lasagne library is not loaded\n",
    "first \"import theano\", then \"git clone https://github.com/Lasagne/Lasagne.git\", followed by \"cd Lasagne\" and then \"sudo -H python setup.py install\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from jupyter_core.paths import jupyter_data_dir\n",
    "print(jupyter_data_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.5/bin/python3')\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages')\n",
    "#sys.path.append('/home/misko/anaconda3')\n",
    "#sys.path.append('/home/misko/anaconda3/lib/python3.5/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Telling matplotlib to plot graphs inline\n",
    "%matplotlib inline \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from matplotlib import cm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GMM\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import theano\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "\n",
    "import _pickle as pickle\n",
    "\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: UNDERSTAND THE PROBLEM\n",
    "### 1. The goal is to detect 15 different keypoints on the face\n",
    "### 2. 7049 training samples are available, some have NaN in attribute fields, needs to be cleaned up\n",
    "### 3. Once cleaned up data is available, study the cleaned up data to see whether cleanup added value\n",
    "### 4. Run PCA to narrow down the dimensionality\n",
    "### 5. With narrowed dimensionality, train and predict using Neural nets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: LOAD THE DATA AND DO BASIC CLEANUP\n",
    "\n",
    "Loading train data and getting some information about its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FTRAIN = 'data/training.csv'\n",
    "FTEST = 'data/test.csv'\n",
    "\n",
    "def load(test=False, cols=None, logging=True):\n",
    "    \"\"\"Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n",
    "    Pass a list of *cols* if you're only interested in a subset of the\n",
    "    target columns.\n",
    "    \"\"\"\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = read_csv(os.path.expanduser(fname))  # load pandas dataframe\n",
    "\n",
    "    # The Image column has pixel values separated by space; convert\n",
    "    # the values to numpy arrays:\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    if cols:  # get a subset of columns\n",
    "        df = df[list(cols) + ['Image']]\n",
    "\n",
    "    # Just for the visual record, have the data printed out\n",
    "    print(df.count())  # prints the number of values for each column\n",
    " \n",
    "    # Get all the rows that have some NA fields\n",
    "    dfna = df[df.isnull().any(axis=1)]\n",
    "\n",
    "    # For the first level of processing, use only the records that have\n",
    "    # complete data (no NaN)\n",
    "    df = df.dropna()  # drop all rows that have missing values in them\n",
    "\n",
    "    # Stick to 4 decimal points in order to have well formatted output\n",
    "    # There are 2 dataframes\n",
    "    #    df - dataframe with complete data\n",
    "    #    dfna - dataframe with records that have NaN\n",
    "    df.round(4)\n",
    "    dfna.round(4)\n",
    "    \n",
    "    # Return processed data and the 2 dataframes\n",
    "    return df, dfna\n",
    "\n",
    "\n",
    "# Load the data\n",
    "train_df, train_dfna = load()\n",
    "test_df, test_dfna = load(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Cleanup\n",
    "### Dealing with rows that have NAs\n",
    "#### 1. 4909 rows have NAs in some fields. These rows otherwise carry important information and this information in other columns must somehow be used. \n",
    "#### 2. 2140 rows have complete information and can used as a training set.\n",
    "#### 3. The the field averages from the complete set and use the field averages to fill in and complete the set with NaNs\n",
    "#### 4. This approach will provide a full 7049 rows if data that can be used for building predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If true, program attempts to fix images with missing keypoints\n",
    "include_errors = False\n",
    "\n",
    "def repair_dataset(train_df=train_df, train_dfna=train_dfna, logging=True): \n",
    "    # How many rows have null features exist?\n",
    "    dfnacheck_before = len(train_dfna[train_dfna.isnull().any(axis=1)])\n",
    "    if (logging==True):\n",
    "        print(\"Rows with NA features before cleanup: %d\" % dfnacheck_before)\n",
    "\n",
    "    # Now compute the average of every column and use the averages to fill in the NaN fields in dfna\n",
    "    for feature in train_dfna:\n",
    "        if feature != 'Image':\n",
    "            mean = train_df[feature].mean() * 1.0\n",
    "            train_dfna[feature] = train_dfna[feature].fillna(mean)\n",
    "\n",
    "    # Assert that all null features have been dealt with.\n",
    "    dfnacheck_after = len(train_dfna[train_dfna.isnull().any(axis=1)])\n",
    "    assert(dfnacheck_after == 0)\n",
    "    if (logging==True):\n",
    "        print(\"Rows with NA features after cleanup: %d\" % dfnacheck_after)\n",
    "\n",
    "    # Merge the df and dfna dataframes together to create a much larger data set\n",
    "    #repaired = pd.concat([train_df, train_dfna])\n",
    "    repaired = train_df.append(train_dfna)\n",
    "\n",
    "    if (logging==True):\n",
    "        print(\"Size of corrected dataset: %d\" % len(repaired))\n",
    "    return repaired\n",
    "\n",
    "# Finish creating the data\n",
    "def get_data(df, test=False, col=None, logging=True):\n",
    "    if logging==True:\n",
    "        print(df.count())\n",
    "    \n",
    "    # Normalize the given data\n",
    "    X = np.vstack(df['Image'].values) / 255.  # scale pixel values to [0, 1]\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    if not test:  # only FTRAIN has any target columns\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48 # scale target coordinates to [-1, 1]\n",
    "        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n",
    "        y = y.astype(np.float32)\n",
    "        \n",
    "    else:\n",
    "        y = None\n",
    "    return X, y\n",
    "\n",
    "if include_errors == True:\n",
    "    repaired_df = repair_dataset()\n",
    "    train_data, train_labels = get_data(repaired_df, logging=False)\n",
    "else:\n",
    "    train_data, train_labels = get_data(train_df, logging=False)\n",
    "test_data, test_labels = get_data(test_df,test=True, logging=False)\n",
    "\n",
    "# Print out data boundaries\n",
    "print(\"train_data.shape == {}; train_labels.min == {:.3f}; train_labels.max == {:.3f}\".format(\n",
    "        train_data.shape, train_data.min(), train_data.max()))\n",
    "print(\"train_labels.shape == {}; y.min == {:.3f}; y.max == {:.3f}\".format(\n",
    "        train_labels.shape, train_labels.min(), train_labels.max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(test_data.shape)\n",
    "# test labels do not exist, cannot check for tes_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For data visualization, need a plot routine\n",
    "### Copy the plot code as published in \n",
    "https://www.ischool.berkeley.edu/sites/default/files/projects/14-dailey_jang_oneto_yang_final.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compare_images(image1, p1, image2, p2): \n",
    "    p1 = p1 * 48 + 48\n",
    "    p2 = p2 * 48 + 48\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.subplot(1,2,1) \n",
    "    plt.imshow(np.reshape(image1,(96,96)), cmap = cm.gray) \n",
    "    for x, y in np.reshape(p1,(len(p1)/2, 2)):\n",
    "        plt.plot(x, y, 'r.')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2) \n",
    "    plt.imshow(np.reshape(image2,(96,96)), cmap = cm.gray) \n",
    "    for x, y in np.reshape(p2,(len(p2)/2, 2)):\n",
    "        plt.plot(x, y, 'r.')\n",
    "    plt.axis('off')\n",
    "\n",
    "# Keep data consistent.\n",
    "np.random.seed(0)\n",
    "sample = np.floor(np.random.rand(2, 2) * len(train_data))\n",
    "\n",
    "print(\"Display some sample images with their keypoints:\")\n",
    "for i in sample:\n",
    "    compare_images(train_data[i[0]], train_labels[i[0]], train_data[i[1]], train_labels[i[1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 : Set up plotting\n",
    "\n",
    "Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def graph_results(net):\n",
    "    train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "    valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "    plt.plot(train_loss, linewidth=3, label=\"train\")\n",
    "    plt.plot(valid_loss, linewidth=3, label=\"valid\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.ylim(1e-4, 1e-2)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Adjustment: Algorithm # 1\n",
    "### Histogram Stretching\n",
    "A simple way of image enhancement that improves the contrast in an image by stretching the range of pixel intensity to span the entire range from minimum (0) to maximum (1). Over 8 bits, this algorithm expands the contrast in the image over the entire 0 to 255 range\n",
    "\n",
    "The reference article is:\n",
    "http://cs229.stanford.edu/proj2014/Yue%20Wang,Yang%20Song,Facial%20Keypoints%20Detection.pdf\n",
    "#### Ref: Facial Keypoints Detection, by Yue Wang and Yang Song, Stanford University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compare_histograms(frame1, frame2):\n",
    "        fig = plt.figure(figsize=(16,8))\n",
    "        # the histogram of the data\n",
    "        fig.add_subplot(1,2,1)\n",
    "        n, bins, patches = plt.hist(frame1, 20, facecolor='green')\n",
    "        l = plt.plot(bins, 'r--', linewidth=1)\n",
    "\n",
    "        plt.xlabel('Pixel value')\n",
    "        plt.ylabel('Pixel Count')\n",
    "        plt.title('Pre-Histogram Transformation')\n",
    "        plt.axis([0, 1, 0, 3000])\n",
    "        plt.grid(True)\n",
    "\n",
    "        fig.add_subplot(1,2,2)\n",
    "        n, bins, patches = plt.hist(frame2, 20, facecolor='green')\n",
    "        l = plt.plot(bins, 'r--', linewidth=1)\n",
    "\n",
    "        plt.xlabel('Pixel value')\n",
    "        plt.ylabel('Pixel Count')\n",
    "        plt.title('Post-Histogram Transformation')\n",
    "        plt.axis([0, 1, 0, 3000])\n",
    "        plt.grid(True)\n",
    "\n",
    "\n",
    "def stretch_histogram(frame):\n",
    "    # Save the incoming \n",
    "    new_frame = []\n",
    "    \n",
    "    # Algorithm is very sensitive to outliers at both ends\n",
    "    # So, focus on the 5th and 95th percentile points as as proposed by Song et al.\n",
    "    a = np.percentile(frame, 5)\n",
    "    b = np.percentile(frame, 95)\n",
    "    u = 1 # desired_max_pixel_value\n",
    "    l = 0 # desired_min_pixel_value\n",
    "\n",
    "    # Algorithm fails to optimize if low and high values are at the extreme\n",
    "    if a == 0 and b == 1:\n",
    "        return(frame)\n",
    "    \n",
    "    # If frame is all white or all black, skip processing\n",
    "    if a == 1 or b == 0:\n",
    "        return(frame)\n",
    "\n",
    "    for x in range(0, len(frame)):\n",
    "        if (frame[x] > b):\n",
    "            new_frame.append(np.float32(1.0))\n",
    "        elif (frame[x] < a):\n",
    "            new_frame.append(np.float32(0.0))\n",
    "        else:\n",
    "            p_prime = np.float32(((u - l) / (b - a)) * (frame[x] - a) - l)\n",
    "            new_frame.append(p_prime)\n",
    "            if (p_prime < 0) | (p_prime > 1):\n",
    "                pass\n",
    "                #print(x, p_prime)\n",
    "    #print(np.array(new_frame))\n",
    "    return np.array(new_frame).astype(np.float32)\n",
    "\n",
    "# Keep data consistent.\n",
    "np.random.seed(0)\n",
    "sample = np.random.rand(2) * len(train_data)\n",
    "\n",
    "for i in sample:\n",
    "    before = train_data[i]\n",
    "    after = stretch_histogram(train_data[i])\n",
    "\n",
    "    #compare_histograms(before, after)\n",
    "    compare_images(before, train_labels[i], after, train_labels[i])\n",
    "\n",
    "\n",
    "# For python v2\n",
    "start = time.time()\n",
    "train_stretched = np.array(map(stretch_histogram, train_data))\n",
    "print(\"Finished stretching sample train_data map in %4f seconds\" % (time.time() - start))\n",
    "\n",
    "\n",
    "# For python v3\n",
    "# Routine to stretch all histograms in training data\n",
    "def stretch_histogram_all(train_data=train_data):\n",
    "    train_hist_stretch = np.zeros((len(train_data), 9216))\n",
    "    for index in range(0, len(train_data)):\n",
    "        train_hist_stretch[index] = np.array(stretch_histogram(train_data[index]))\n",
    "    return np.array(train_hist_stretch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Adjustment: Algorithm # 2\n",
    "### Histogram Shifting\n",
    "A simple way of image enhancement that improves the contrast in an image by shifting the intensity of the pixels to the right. Lighter pixels are darker and darker pixels are enhanced. \n",
    "The reference article is: www.tutorialspoint.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load data and shift\n",
    "def shift_histogram_right(frame, shift=0.3):\n",
    "    \n",
    "    new_frame = []\n",
    "    \n",
    "    for i in range(0, len(frame)):\n",
    "        new_value = frame[i] + shift\n",
    "        if new_value > 1.0:\n",
    "            new_frame.append(np.float64(1.0))\n",
    "        else:\n",
    "            new_frame.append(new_value)\n",
    "    \n",
    "    return np.array(new_frame).astype(np.float32)\n",
    "\n",
    "\n",
    "# Keep data consistent.\n",
    "np.random.seed(0)\n",
    "sample = np.random.rand(2) * len(train_data)\n",
    "\n",
    "# Amount of right shift\n",
    "r_shift = 0.30\n",
    "\n",
    "\n",
    "for i in sample:\n",
    "    before = train_data[i]\n",
    "    after = shift_histogram_right(train_data[i], shift=r_shift)\n",
    "    #compare_histograms(before, after)\n",
    "    compare_images(before, train_labels[i], after, train_labels[i])\n",
    "\n",
    "# Looks like everything is working well, generate the new set of data to go forward with\n",
    "start = time.time()\n",
    "\n",
    "# train_shift_right = np.array(map(shift_histogram_right, train_data))\n",
    "# print(\"Finished shifting RIGHT train_data in %4f seconds\" % (time.time() - start))\n",
    "\n",
    "# Load data and shift\n",
    "def shift_histogram_left(frame, shift=0.15):\n",
    "    new_frame = []\n",
    "    \n",
    "    for i in range(0, len(frame)):\n",
    "        new_value = frame[i] - shift\n",
    "        if new_value < 0.0:\n",
    "            new_frame.append(np.float64(0.0))\n",
    "        else:\n",
    "            new_frame.append(new_value)\n",
    "    \n",
    "    return np.array(new_frame).astype(np.float32)\n",
    "\n",
    "\n",
    "# Keep data consistent.\n",
    "np.random.seed(0)\n",
    "sample = np.random.rand(2) * len(train_data)\n",
    "\n",
    "# Amount of left shift\n",
    "l_shift = 0.2\n",
    "\n",
    "for i in sample:\n",
    "    before = train_data[i]\n",
    "    after = shift_histogram_left(train_data[i], shift=l_shift)\n",
    "    #compare_histograms(before, after)\n",
    "    compare_images(before, train_labels[i], after, train_labels[i])\n",
    "\n",
    "# Looks like everything is working well, generate the new set of data to go forward with\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# For python v3\n",
    "# Routine(s) to shift all histograms in training data\n",
    "def shift_histogram_right_all(train_data=train_data):\n",
    "    train_shift_right = np.zeros((len(train_data), train_data.shape[1]))\n",
    "    for index in range(0, len(train_data)):\n",
    "        train_shift_right[index] = np.array(shift_histogram_right(train_data[index]))\n",
    "    return np.array(train_shift_right)\n",
    "\n",
    "def shift_histogram_left_all(train_data=train_data):\n",
    "    train_shift_left = np.zeros((len(train_data), train_data.shape[1]))\n",
    "    for index in range(0, len(train_data)):\n",
    "        train_shift_left[index] = np.array(shift_histogram_left(train_data[index]))\n",
    "    return np.array(train_shift_left)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Blur\n",
    "\n",
    "Gaussian Blur changes cell values to a weighted average of surrounding cells.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gaussian_blur(origin, matrix, blur=1):\n",
    "    sd = 2\n",
    "    pi = np.pi\n",
    "    e = np.e\n",
    "    cartesian = []\n",
    "    coords = []\n",
    "    weights = []\n",
    "    blurred_pixel = 0.0\n",
    "\n",
    "    x = origin[0]\n",
    "    y = origin[1]\n",
    "    \n",
    "    for i in range(-blur, blur):\n",
    "        for j in range(-blur, blur):\n",
    "            cartesian.append([i, j])\n",
    "            try:\n",
    "                if ((x - i) == 0) | ((y - j) == 0):\n",
    "                    raise IndexError\n",
    "                coords.append(matrix[x + i][y + j])\n",
    "            except IndexError:\n",
    "                coords.append(matrix[x][y])\n",
    "    weights = []\n",
    "    for pair in cartesian:\n",
    "        x = pair[0]\n",
    "        y = pair[1]\n",
    "        weight = (1.0 / (2 * pi * sd ** 2)) * (e ** -((x ** 2 + y ** 2) / (2 * sd ** 2))) # 2D Gaussian function\n",
    "        weights.append(weight)\n",
    "    averages = [w / sum(weights) for w in weights]\n",
    "    for i in range(0, len(coords)):\n",
    "        blurred_pixel += coords[i] * averages[i]\n",
    "\n",
    "    return blurred_pixel\n",
    "\n",
    "def apply_blur(img):\n",
    "    blurred_matrix = []\n",
    "    matrix = img.reshape(96, 96)\n",
    "    for row in range(0, len(matrix)):\n",
    "        for col in range(0, len(matrix[row])):\n",
    "            origin = [row, col]\n",
    "            blurred_matrix.append(gaussian_blur(origin, matrix))\n",
    "    return np.array(blurred_matrix).astype(np.float32)\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for i in sample:\n",
    "    before = train_data[i]\n",
    "    after = apply_blur(train_data[i])\n",
    "    #compare_histograms(before, after)\n",
    "    compare_images(before, train_labels[i], after, train_labels[i])\n",
    "\n",
    "# # Looks like everything is working well, generate the new set of data to go forward with\n",
    "# start = time.time()\n",
    "# train_blur = np.array(map(apply_blur, train_data))\n",
    "# print(\"Finished blurring train_data in %4f seconds\" % (time.time() - start))\n",
    "\n",
    "\n",
    "# For python v3\n",
    "# Routine to gaussian shift all the images in the training data\n",
    "def apply_blur_all(train_data=train_data):\n",
    "    blur_all = np.zeros((len(train_data), 9216))\n",
    "    for index in range(0, len(train_data)):\n",
    "        blur_all[index] = np.array(apply_blur(train_data[index]))\n",
    "    return np.array(blur_all)\n",
    "\n",
    "# start = time.time()\n",
    "# print(\"starting blurring of all frames\")\n",
    "# train_blur_all = apply_blur_all()\n",
    "# print(\"Finished blurring all train_data in %4f seconds\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical Pixel Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The labels and their indexes\n",
    "critical_points = [\"left_eye_center_x\", \"left_eye_center_y\", \n",
    "                       \"right_eye_center_x\", \"right_eye_center_y\",\n",
    "                       \"left_eye_inner_corner_x\", \"left_eye_inner_corner_y\", \n",
    "                       \"left_eye_outer_corner_x\", \"left_eye_outer_corner_y\",\n",
    "                       \"right_eye_inner_corner_x\", \"right_eye_inner_corner_y\",\n",
    "                        \"right_eye_outer_corner_x\", \"right_eye_outer_corner_y\",\n",
    "                       \"left_eyebrow_inner_end_x\", \"left_eyebrow_inner_end_y\",\n",
    "                       \"left_eyebrow_outer_end_x\", \"left_eyebrow_outer_end_y\",\n",
    "                       \"right_eyebrow_inner_end_x \", \"right_eyebrow_inner_end_y\", \n",
    "                       \"right_eyebrow_outer_end_x\", \"right_eyebrow_outer_end_y\",\n",
    "                       \"nose_tip_x\", \"nose_tip_y\",\n",
    "                        \"mouth_left_corner_x\", \"mouth_left_corner_y\",\n",
    "                       \"mouth_right_corner_x\", \"mouth_right_corner_y\", \n",
    "                      \"mouth_center_bottom_lip_x\", \"mouth_center_bottom_lip_y\", \n",
    "                       \"mouth_center_top_lip_x\", \"mouth_center_top_lip_y\"\n",
    "                  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRITICAL PIXEL ENHANCEMENT - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "# This function sets up the 9 bins for digitizing the data for a frame X\n",
    "def setup_heatmap(X):\n",
    "    bins = np.arange(0, 1.0, 0.111) # Set up 9 bins for holding data\n",
    "    \n",
    "    # digitize the incoming data into bins\n",
    "    binplace = np.digitize(X, bins, right=True)\n",
    "    \n",
    "    # Flatten for vector processing\n",
    "    binplace = binplace.flatten()\n",
    "    \n",
    "    # return the bins\n",
    "    return binplace\n",
    "\n",
    "\n",
    "def computeCentroid(eye_1, eye_2):\n",
    "    \n",
    "    #print(eye_1, eye_2)\n",
    "    center_eye_1 = [0,0]\n",
    "    center_eye_2 = [0,0]\n",
    "    \n",
    "    if len(eye_1) > 0 and len(eye_2) > 0:\n",
    "        # Put all the eye data together\n",
    "        # print(len(eye_1), len(eye_2))\n",
    "        eye_1_x,eye_1_y=list(zip(*eye_1))\n",
    "        eye_2_x,eye_2_y=list(zip(*eye_2))\n",
    "    \n",
    "        # Compute the centroid coordinates. There most likley is a better formula\n",
    "        center_eye_1=sum(eye_1_x)/len(eye_1), sum(eye_1_y)/len(eye_1)\n",
    "        center_eye_2=sum(eye_2_x)/len(eye_2), sum(eye_2_y)/len(eye_2)\n",
    "    \n",
    "    return center_eye_1, center_eye_2\n",
    "\n",
    "def PreProcessFrame(data, labels, plot=False):\n",
    "\n",
    "    X = process_image(data, labels, plot=plot)\n",
    "\n",
    "    labels = labels * 48 + 48\n",
    "    # Attach a color with each bin, in this case 9 colors, one for each bin\n",
    "    # We are not interested in all colors, only the colors that highlight the eyes. \n",
    "    # so, make other colors \"white\" so that they do not show.\n",
    "    # Determined through trial and error that bins 2 and 3 are the best bins for the eyes\n",
    "    cmap = colors.ListedColormap(['white', 'white', 'orange', 'red', 'white', 'white', 'white', 'white', 'white'])\n",
    "    bounds=[0.05, 0.08, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 1.0]\n",
    "    norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    # Create the digitized 9 bins\n",
    "    binplace = setup_heatmap(X)\n",
    "\n",
    "    # Flatten for further use into a 9216 array\n",
    "    X_flattened = X.flatten()\n",
    "    return binplace, X, X_flattened, labels\n",
    "\n",
    "def determine_eye_coordinates(eye_indices):\n",
    "    \n",
    "    # Two lists are needed to hold the pixels that \n",
    "    # represent each eye\n",
    "    eye_1_pos = []\n",
    "    eye_2_pos = []\n",
    "\n",
    "    processed_flag = 0\n",
    "    # The eyes are usually part of the dark pixels in the images\n",
    "    # And dark pixels are captured in the lowest 3 digitized bins. Learned through \n",
    "    # trial and error by observing the heat maps of multiple images\n",
    "\n",
    "    # Now extract the two eye sets\n",
    "    # The eyes fall within rectangles defined by multiple rows and columns\n",
    "    # Each pixel is represented by a (row * column) number \n",
    "    # Start the count from the top left of the photo\n",
    "    # The two rectangles are through the observation of multiple images\n",
    "    for item in eye_indices:\n",
    "        #print(\"Item is {}\".format(item))\n",
    "        if (item > 2900 and item < 2920) or \\\n",
    "            (item > 2996 and item < 3016) or \\\n",
    "            (item > 3092 and item < 3112) or \\\n",
    "            (item > 3188 and item < 3208) or \\\n",
    "            (item > 3284 and item < 3304) or \\\n",
    "            (item > 3380 and item < 3400) or \\\n",
    "            (item > 3476 and item < 3496) or \\\n",
    "            (item > 3572 and item < 3592) or \\\n",
    "            (item > 3668 and item < 3688) or \\\n",
    "            (item > 3764 and item < 3784) or \\\n",
    "            (item > 3860 and item < 3880):\n",
    "            \n",
    "            processed_flag = 1\n",
    "            #print(\"Processed eye 1 {}\".format(item))\n",
    "            \n",
    "            eye_1_pos_y = item//96  # The whole number part is the row or y\n",
    "            eye_1_pos_x = item%96 # The fractional part is the column or x\n",
    "        \n",
    "            #print(eye_1_pos_x, eye_1_pos_y)\n",
    "            # Add to a list that defines eye number 1\n",
    "            eye_1_pos.append((eye_1_pos_x, eye_1_pos_y))\n",
    "        \n",
    "        # Do exactly the above for the second eye. Only the bounding rectangle is different\n",
    "        elif (item > 2939 and item < 2959) or \\\n",
    "            (item > 3035 and item < 3055) or \\\n",
    "            (item > 3131 and item < 3151) or \\\n",
    "            (item > 3227 and item < 3247) or \\\n",
    "            (item > 3323 and item < 3343) or \\\n",
    "            (item > 3419 and item < 3439) or \\\n",
    "            (item > 3515 and item < 3535) or \\\n",
    "            (item > 3611 and item < 3631) or \\\n",
    "            (item > 3707 and item < 3727) or \\\n",
    "            (item > 3803 and item < 3823) or \\\n",
    "            (item > 3899 and item < 3919):\n",
    "            \n",
    "            processed_flag = 1\n",
    "            #print(\"Processed eye 2 {}\".format(item))\n",
    "            \n",
    "            eye_2_pos_y = item//96\n",
    "            eye_2_pos_x = item%96\n",
    "        \n",
    "            #print(eye_2_pos_x, eye_2_pos_y)\n",
    "            # List of pixels that define the second eye\n",
    "            eye_2_pos.append((eye_2_pos_x, eye_2_pos_y))\n",
    "\n",
    "    if processed_flag == 0:\n",
    "        eye_1_pos = [(0,0)]\n",
    "        eye_2_pos = [(0,0)]\n",
    "        \n",
    "    # Return the pixel coordinates of the 2 eye clusters\n",
    "    return (eye_1_pos, eye_2_pos)\n",
    "\n",
    "\n",
    "def VerifyAndFixEyeCoordinates(binplace, eye_1, eye_2, logging=False):\n",
    "    # There is a possibility that the first chosen 2 bins do not have any eye pixel\n",
    "    # Successively add a bin until there are non-zero data points in the eye rectangle\n",
    "    # This is kludgy stuff - my apologies!\n",
    "    processed_flag = 0\n",
    "    if len(eye_1)==0 or len(eye_2)==0:\n",
    "        if logging==True:\n",
    "            print(\"Adding a bin\")\n",
    "        eye_indices = list(np.where((binplace==1)|(binplace==2)|(binplace==3))[0])\n",
    "        eye_1, eye_2 = determine_eye_coordinates(eye_indices)\n",
    "        if len(eye_1)==0 or len(eye_2)==0:\n",
    "            if logging==True:\n",
    "                print(\"Adding another bin\")\n",
    "            eye_indices = list(np.where((binplace==1)|(binplace==2)|(binplace==3)|(binplace==4))[0])\n",
    "            eye_1, eye_2 = determine_eye_coordinates(eye_indices)\n",
    "            if len(eye_1)==0 or len(eye_2)==0:\n",
    "                if logging==True:\n",
    "                    print(\"Adding yet another bin \")\n",
    "                eye_indices = list(np.where((binplace==1)|(binplace==2)|(binplace==3)|(binplace==4)|(binplace==5))[0])\n",
    "                eye_1, eye_2 = determine_eye_coordinates(eye_indices)\n",
    "                if len(eye_1)==0 or len(eye_2)==0:\n",
    "                    if logging==True:\n",
    "                        print(\"Adding the last 4 bins - the last attempt\")\n",
    "                    eye_indices = list(np.where((binplace==1)|(binplace==2)|(binplace==3)|(binplace==4)|\\\n",
    "                                        (binplace==5)|(binplace==6)|(binplace==7)|(binplace==8)|(binplace==9))[0])\n",
    "                    eye_1, eye_2 = determine_eye_coordinates(eye_indices)\n",
    "                    if len(eye_1)==0 or len(eye_2)==0:\n",
    "                        eye_1=[]\n",
    "                        eye_2=[]\n",
    "                        if (logging==True):\n",
    "                            print(\"Could not find eye pixels\")\n",
    "    return(eye_1, eye_2)\n",
    "\n",
    "def reduce_and_darken_narrower_area(frame, eye_1, eye_2):\n",
    "\n",
    "    if len(eye_1) > 6:\n",
    "        del eye_1[int(2*len(eye_1)/3):] # delete the upper third\n",
    "    \n",
    "\n",
    "    if len(eye_1) > 6:\n",
    "        eye_1 = eye_1[int(len(eye_1)/3):] # Remove the bottom third\n",
    "    \n",
    "    if len(eye_2) > 6:\n",
    "        del eye_2[int(2* len(eye_2)/3):] # delete the upper third\n",
    "        \n",
    "    if len(eye_2) > 6:\n",
    "        eye_2 = eye_2[int(len(eye_2)/3):] # Remove the bottom third\n",
    "\n",
    "    # Eye1 1: For all remaining eye pixels, darken them by moving left\n",
    "    for x in eye_1:\n",
    "        #print(\"First eye coordinates {}\". format(x))\n",
    "        z = x[0] + x[1] * 96\n",
    "        \n",
    "        frame[z] -= 0.3 # Darken the pixel\n",
    "        if frame[z] < 0:\n",
    "            frame[z] = 0 # Don't go negative with darkening\n",
    "    \n",
    "    # Eye 2: For all remaining eye pixels, darken them by moving left\n",
    "    for x in eye_2:\n",
    "        #print(\"Second eye coordinates {}\". format(x))\n",
    "        z = x[0] + x[1] * 96\n",
    "        \n",
    "        frame[z] -= 0.2 # Darken the pixel\n",
    "        if frame[z] < 0:\n",
    "            frame[z] = 0 # Don't go negative with darkening\n",
    "    return frame\n",
    "\n",
    "def darken_eyes(frame, logging = False):\n",
    "\n",
    "    #print(\"New Frame\")\n",
    "    X = np.reshape(frame,(96,96))\n",
    "\n",
    "    # Create the digitized 9 bins\n",
    "    binplace = setup_heatmap(X)\n",
    "\n",
    "    # Flatten for further use into a 9216 array\n",
    "    X_flattened = X.flatten()\n",
    "    \n",
    "    # Start with assumption that 1 and 2 are the bins within which the eye resides\n",
    "    eye_indices = list(np.where((binplace==1)|(binplace==2))[0])\n",
    "\n",
    "    #print(\"darken_eyes: eye indices are {}\".format(eye_indices))\n",
    "    # Given the bins, find the eye coordinates\n",
    "    eye_1, eye_2 = determine_eye_coordinates(eye_indices)\n",
    "    #print(\"darken_eyes: determined eye indices are {}\".format(eye_1, eye_2))\n",
    "    \n",
    "    if len(eye_1)==0 or len(eye_2)==0:\n",
    "        frame = shift_histogram_left(frame, shift=0.2)\n",
    "        if logging==True:\n",
    "            print(\"darken_eyes: Left shifted the image\")\n",
    "        eye_1, eye_2 = VerifyAndFixEyeCoordinates(binplace, eye_1, eye_2, logging=False)\n",
    "        \n",
    "    eye_1, eye_2 = VerifyAndFixEyeCoordinates(binplace, eye_1, eye_2, logging=False)\n",
    "    \n",
    "    # compute the centroid of both eyes\n",
    "    #print(eye_1, eye_2)\n",
    "    centroid_eye_1, centroid_eye_2 = computeCentroid(eye_1, eye_2)\n",
    "    #print(\"Centroid is {} {}\".format(centroid_eye_1, centroid_eye_2))\n",
    "    # be selective about how many spots to darken. Stay close to the centroid\n",
    "    # Visit at a later time\n",
    "    \n",
    "    if logging == True:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.imshow(np.reshape(frame,(96,96)), cmap = cm.gray) \n",
    "    \n",
    "    # Darken just the Centroids\n",
    "    z1 = centroid_eye_1[0] + 96 * centroid_eye_1[1]\n",
    "    z2 = centroid_eye_2[0] + 96 * centroid_eye_2[1]\n",
    "    frame[z1] -= 0.15 # Darken the pixel\n",
    "    frame[z2] -= 0.15 # Darken the pixel\n",
    "    \n",
    "    # Centoid has been darkened\n",
    "    # Now work on the middle items in the list of eye pixels, ignore the outliers\n",
    "    #frame = reduce_and_darken_narrower_area(frame, eye_1, eye_2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Routine to loop through and darken all eyes in all images in training data\n",
    "def darken_eyes_all(images, logging=False):\n",
    "    for i in range(0, len(images)):\n",
    "        #print(\"The image index is {}\".format(i))\n",
    "        images[i] = darken_eyes(images[i])\n",
    "    return(np.array(images))\n",
    "\n",
    "# IGNORE THIS ROUTINE FOR NOW, IT IS NOT USED\n",
    "def enhance_critical_points(frame, attributes):\n",
    "\n",
    "    # unscale the attribute form its -1, 1 boundaries\n",
    "    attributes = attributes * 48 + 48\n",
    "\n",
    "    #attribute = attribute[[6,7,10, 11, 20, 21, 22, 23, 24, 25]]\n",
    "    attributes = attributes[[0,1]]\n",
    "    #print(len(attribute))\n",
    "    critical_pixels = [] * len(attributes)\n",
    "    #attribute = attribute * 48 + 48\n",
    "    for x, y in np.reshape(attributes,(len(attributes)/2, 2)):\n",
    "        #print(x,y)\n",
    "        critical_pixels.append(int((x*y)))\n",
    "        #print(\"x, y is {}  {} {}\".format(x,y, x*y))\n",
    "\n",
    "    # Amount by which to increase the area around each critical point\n",
    "    shift = 0.5\n",
    "\n",
    "    # Loop for every one of 10 critical features\n",
    "    #for index in feature_index:\n",
    "    count = 0\n",
    "    for pixel_value in critical_pixels:\n",
    "        z = frame[pixel_value]\n",
    "        #print(z)\n",
    "        if z-shift >= 0:\n",
    "            frame[pixel_value] -= shift\n",
    "        else :\n",
    "            frame[pixel_value] = 0\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    # Return the critical point enhanced frame \n",
    "    return np.array(frame).astype(np.float32)\n",
    "\n",
    "cpe_dataset = repair_dataset(logging=False)\n",
    "X_CPE, y_CPE = get_data(cpe_dataset, logging=False)\n",
    "\n",
    "np.random.seed(22)\n",
    "sample = np.random.rand(5) * len(X_CPE)\n",
    "\n",
    "\n",
    "# Routine to loop through and enhance all eyes in all images\n",
    "def enhance_critical_points_all(frame=train_data, attributes=train_labels):\n",
    "    train_enhanced_eyes = np.zeros((len(train_data), 9216))\n",
    "    for index in range(0, len(train_data)):\n",
    "        #train_enhanced_eyes[index] = np.array(enhance_critical_points(train_data[index], attributes[index]))\n",
    "        train_enhanced_eyes[index] = np.array(darken_eyes(train_data[index]))\n",
    "    return np.array(train_enhanced_eyes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE ROTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Given one frame and coordinates of its labels...\n",
    "# \n",
    "# If \"plot\" is True, show the red dots on the image and return a 96 by 96 matrix\n",
    "# If \"plot\" is False, just return a 96 by 96 matrix\n",
    "def process_image(image, labels, plot=False): \n",
    "\n",
    "    if plot == True:\n",
    "        labels = labels * 48 + 48\n",
    "        #plt.figure(figsize=(8, 4))\n",
    "        #print(\"process_image I\")\n",
    "        plt.imshow(np.reshape(image,(96,96)), cmap = cm.gray) \n",
    "        for x, y in np.reshape(labels,(len(labels)/2, 2)):\n",
    "            plt.plot(x, y, 'r.')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return np.reshape(image,(96,96))\n",
    "\n",
    "\n",
    "from math import *\n",
    "\n",
    "def getAngleBetweenPoints(x_1, y_1, x_2, y_2):\n",
    "    deltaY = y_2 - y_1\n",
    "    deltaX = x_2 - x_1\n",
    "    angle = atan2(deltaY, deltaX) # angle in radians\n",
    "    \n",
    "    # convert angle to degrees and return\n",
    "    return angle * 180/pi\n",
    "\n",
    "\n",
    "def rotate_point(centerPoint,point,angle):\n",
    "    angle = math.radians(angle)\n",
    "    temp_point = point[0]-centerPoint[0] , point[1]-centerPoint[1]\n",
    "    temp_point = ( temp_point[0]*math.cos(angle)-temp_point[1]*math.sin(angle) , \\\n",
    "                              temp_point[0]*math.sin(angle)+temp_point[1]*math.cos(angle))\n",
    "    temp_point = temp_point[0]+centerPoint[0] , temp_point[1]+centerPoint[1]\n",
    "    return temp_point\n",
    "\n",
    "def rotate_labels(labels, label_count, axis, angle):\n",
    "    labels_rotated=[]\n",
    "\n",
    "    for i in range(0, label_count, 2):\n",
    "        point=[labels[i], labels[i+1]]\n",
    "        new_x, new_y = rotate_point(axis, point, angle)\n",
    "        labels_rotated.append((new_x, new_y))\n",
    "    return labels_rotated\n",
    "\n",
    "from matplotlib import colors\n",
    "from skimage import data\n",
    "from skimage.transform import rotate\n",
    "\n",
    "# Rotate the image\n",
    "# \"data\" here is one image frame\n",
    "def image_rotate(data=train_data, labels=train_labels, plot=False, \\\n",
    "                                                 logging = False, label_count=30):\n",
    "\n",
    "    # ensure that the rotation direction is logged\n",
    "    rotation_direction=1  # anti-clockwise by default\n",
    "    angle = 0\n",
    "    \n",
    "    \n",
    "    # Preprocess the data \n",
    "    binplace, X, X_flattened, labels = PreProcessFrame(data, labels, plot=plot)\n",
    "\n",
    "    # Start with assumption that 1 and 2 are the bins within which the eye resides\n",
    "    eye_indices = list(np.where((binplace==1)|(binplace==2))[0])\n",
    "    \n",
    "    # Given the bins, find the eye coordinates\n",
    "    eye_1, eye_2 = determine_eye_coordinates(eye_indices)\n",
    "\n",
    "    loopIndex = 0\n",
    "    shift = 0.2\n",
    "    while len(eye_1) == 0 or len(eye_2) == 0:\n",
    "        shift_histogram_left(data, shift = shift)\n",
    "        if logging==True:\n",
    "            print(\"{} attempt at fixing via darkening of image\".format(loopIndex+1))\n",
    "        eye_1, eye_2 = VerifyAndFixEyeCoordinates(binplace, eye_1, eye_2, logging)\n",
    "        if len(eye_1) > 0 and len(eye_2) > 0:\n",
    "            break\n",
    "        else:\n",
    "            if loopIndex == 1:\n",
    "                if logging==True:\n",
    "                    print(\"Eye recognition error I - Image is too light\")\n",
    "                return labels, X_flattened\n",
    "        loopIndex +=1\n",
    "        if loopIndex > 2:\n",
    "            break\n",
    "    \n",
    "    loopIndex = 0\n",
    "    shift = 0.3\n",
    "    while len(eye_1) == 0 or len(eye_2) == 0:\n",
    "        shift_histogram_right(data, shift = shift)\n",
    "        if logging==True:\n",
    "            print(\"{} attempt at fixing via lightening of image\".format(loopIndex+1))\n",
    "        eye_1, eye_2 = VerifyAndFixEyeCoordinates(binplace, eye_1, eye_2)\n",
    "        if len(eye_1) > 0 and len(eye_2) > 0:\n",
    "            break\n",
    "        else:\n",
    "            if loopIndex == 1:\n",
    "                if logging==True:\n",
    "                    print(\"Eye recognition error II - too dark\")\n",
    "                return labels, X_flattened\n",
    "        loopIndex +=1\n",
    "        if loopIndex > 2:\n",
    "            break\n",
    "    \n",
    "    # One last net to catch data where eye cannot be recognized\n",
    "    # If there is a picture where no pixels appear in the eye rectangle,\n",
    "    # we have no choice but to give up. I have not seen this happen. \n",
    "    if len(eye_1)==0 or len(eye_2)==0:\n",
    "        if logging==True:\n",
    "            print(\"Eye index is zero, sending back original data\")\n",
    "        return labels, X_flattened\n",
    "    \n",
    "    # I was not sure how an assignment of X into X_flattened would work, so I decided \n",
    "    # to make an explicit copy. I needed a copy because we are going to munge this\n",
    "    # new frame with rotated pixel values. Start by initializing all pixels to 0\n",
    "    Xcopy = X_flattened.copy()\n",
    "    for i in X_flattened:\n",
    "        Xcopy[i] = 0\n",
    "        \n",
    "    # The visual of having located the eye pixels and overlaying them on the \n",
    "    # original image is powerful\n",
    "    # Plot the eye pixels on top of the original image\n",
    "    if plot==True and logging==True:\n",
    "        plt.scatter(*zip(*eye_1))\n",
    "        plt.scatter(*zip(*eye_2))\n",
    "    \n",
    "    if len(eye_indices) != 0:\n",
    "        for element in eye_indices:\n",
    "            Xcopy[element] = X_flattened[element]\n",
    "    else:\n",
    "        if logging==True:\n",
    "            print(\"eye_indices is zero\")\n",
    "\n",
    "    # Reshape for further processing\n",
    "    Xcopy = np.reshape(Xcopy,(96,96))\n",
    "\n",
    "    center_eye_1, center_eye_2 = computeCentroid(eye_1, eye_2)\n",
    "\n",
    "    if logging==True:\n",
    "        print(\"The centroid values are {} {}\".format(center_eye_1, center_eye_2))\n",
    "\n",
    "    # compute  the angle with the horizontal\n",
    "    # using the coordinates of the 2 eyes\n",
    "    angle = getAngleBetweenPoints(center_eye_1[0], center_eye_1[1], \\\n",
    "                                      center_eye_2[0], center_eye_2[1])\n",
    "\n",
    "    # Needs skimage imports\n",
    "    if (center_eye_2[1] < center_eye_1[1]):\n",
    "        #print(\"Anti clockwise rotation\") because left eye is lower than the right eye, \n",
    "        # right eye is axis\n",
    "        X_rotated = rotate(X, 360 - abs(angle), center = [center_eye_2[0], center_eye_2[1]], \\\n",
    "                                   mode = 'symmetric',\\\n",
    "                                   resize = False, clip = True, preserve_range = True)\n",
    "        #Rotate the labels\n",
    "        if logging==True:\n",
    "            print(\"C angle of rotation is {} {}\".format(angle, radians(angle)))\n",
    "        rotated_labels = rotate_labels(labels, label_count, [center_eye_2[0], \\\n",
    "                                                        center_eye_2[1]], -angle)\n",
    "        angle = 360-angle\n",
    "        rotation_direction=1\n",
    "\n",
    "    else:\n",
    "        #print(\"Anti clockwise rotation\"), right eye is lower than the left eye, left eye is axis\n",
    "        X_rotated = rotate(X, abs(angle), center =[center_eye_1[0], center_eye_1[1]], \\\n",
    "                                   mode='symmetric',\\\n",
    "                                  resize = False, clip = True, preserve_range = True)\n",
    "    \n",
    "        #Rotate the labels\n",
    "        if logging==True:\n",
    "            print(\"AC angle of rotation is {} {}\".format(angle, radians(angle)))\n",
    "        rotated_labels = rotate_labels(labels, label_count, [center_eye_1[0], \\\n",
    "                                                             center_eye_1[1]], -angle)\n",
    "        angle = -angle\n",
    "        rotation_direction=0\n",
    "        \n",
    "    # Not sure why I check but I want  to make sure that we have an array of size 9216\n",
    "    if X_rotated.flatten().shape[0] != 9216:\n",
    "        if logging==True:\n",
    "            print(\"Something wrong {}\".format(X_rotated.flatten().shape[0]))\n",
    "\n",
    "    # Return the rotated image and its parameters\n",
    "    return rotated_labels, X_rotated\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def sample_rotate(train_data=train_data, train_labels=train_labels, sample=100, \\\n",
    "                                              logging=False, label_count=30):\n",
    "    # ROTATION \n",
    "    # The main calls are here\n",
    "    plot=False\n",
    "    # Rotate the images\n",
    "    rotated_labels, rotated_image = image_rotate(data = train_data[sample], \\\n",
    "                        labels = train_labels[sample], plot=plot, logging=logging, \\\n",
    "                                                 label_count=label_count)\n",
    "\n",
    "    if logging==True:\n",
    "        # show the original\n",
    "        plt.imshow(np.reshape(train_data[sample],(96,96)), cmap = cm.gray)\n",
    "        plt.show()\n",
    "\n",
    "        # Now show the rotated image\n",
    "        if rotated_image is not None:\n",
    "            labels = np.array((np.array(rotated_labels) -48)/48)\n",
    "            labels = labels.flatten()\n",
    "            process_image(image = np.array(rotated_image), \\\n",
    "                          labels = labels, plot=True)\n",
    "\n",
    "    return np.array(rotated_image).flatten(), np.array(rotated_labels).flatten()\n",
    "            \n",
    "def sample_rotate_all(train_data=train_data, train_labels=train_labels, label_count=30):\n",
    "\n",
    "    samples = len(train_data)\n",
    "    logging = False\n",
    "    plot = True\n",
    "    # allocate storage for results\n",
    "    print(\"sample_rotate all\")\n",
    "    train_rotated = np.zeros((len(train_data), train_data.shape[1]))\n",
    "    labels_rotated = np.zeros((len(train_data), train_labels.shape[1]))\n",
    "    \n",
    "    # For the training samples\n",
    "    for sample in range(0, samples):\n",
    "            train_rotated[sample], labels_rotated[sample] = \\\n",
    "                        sample_rotate(train_data=train_data, train_labels=train_labels,\\\n",
    "                                        sample=sample, logging=False, label_count=label_count)\n",
    "    print(train_rotated.shape, labels_rotated.shape)\n",
    "    return train_rotated, labels_rotated\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sample_rotate()\n",
    "print(\"Started rotating all\")\n",
    "junk1, junk2 = sample_rotate_all()\n",
    "print(\"End of rotating all\")\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "samples = np.floor(np.random.rand(5) * len(train_data))\n",
    "for sample in samples:\n",
    "    plt.imshow(np.reshape(junk1[sample].flatten(),(96,96)), cmap = cm.gray)\n",
    "    plt.show()\n",
    "#     labels = np.array((np.array(junk2[sample]) -48)/48)\n",
    "#     labels = labels.flatten()\n",
    "#     process_image(image = np.array(junk1[sample]), \\\n",
    "#                           labels = labels, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE REFLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reflect_all_by_y_axis (train_data = train_data, train_labels=train_labels,labels=False,label_count=30,logging=False):\n",
    "\n",
    "    train_data_y_reflection = np.zeros((len(train_data), train_data.shape[1]))\n",
    "    \n",
    "    if labels==True:\n",
    "        train_labels_y_reflection = train_labels.copy()\n",
    "        train_labels_y_reflection = train_labels_y_reflection*48 + 48\n",
    "    \n",
    "    for i in range(0,len(train_data)):\n",
    "\n",
    "        # For debugging only. \n",
    "        if logging==True and (i==300 or i==500 or i==700 or i==1000) and labels==True:\n",
    "            \n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.imshow(np.reshape(train_data[i],(96,96)), cmap = cm.gray)\n",
    "            \n",
    "            #print(train_labels[200])\n",
    "            for x, y in np.reshape(train_labels_y_reflection[i], (len(train_labels_y_reflection[i])/2, 2)):\n",
    "                plt.plot(x, y, 'r.')\n",
    "                plt.title(\"Reflection around the Y axis: Original frame\")\n",
    "                plt.ylim([96,0])\n",
    "                plt.xlim([0,96])\n",
    "\n",
    "        # Make a copy because we will be manipualting the data\n",
    "        train_data_temp = list(train_data[i].copy())\n",
    "        \n",
    "        # we need to loop 96 times (0 to 95), one for each line of pixels\n",
    "        N=0\n",
    "        while N <= 96*95:\n",
    "            \n",
    "            # Read the line of pixels and reverse it\n",
    "            train_data_temp[N:N+96] = train_data_temp[N:N+96][::-1]\n",
    "            \n",
    "            # go to the next line\n",
    "            N += 96\n",
    "        \n",
    "        # Picture has been reflected. Save it and work on labels next\n",
    "        train_data_y_reflection[i] = train_data_temp\n",
    "        \n",
    "        # Now, reflect the labels, if labels = True\n",
    "        # To convert the labels, there are 30 labels, do reflection in pairs, hence step by 2\n",
    "        # y coordinate does not change, only the x coordinate chages. x coordinates are the J \n",
    "        # indices in every pair\n",
    "        # Loop through and stop at 29 because we only have 30 labels\n",
    "        if labels==True:\n",
    "            # use a temporary variable to hold the labels data\n",
    "            labels_tmp = list(train_labels_y_reflection[i])\n",
    "            \n",
    "            if label_count==30:\n",
    "                #flip_indices = [(0, 2), (1, 3),(4, 8), (5, 9), (6, 10), (7, 11),(12, 16), (13, 17),\\\n",
    "                #               (14, 18), (15, 19),(22, 24), (23, 25),]\n",
    "                labels_tmp[0], labels_tmp[2] = 96-labels_tmp[2], 96-labels_tmp[0]\n",
    "                labels_tmp[1], labels_tmp[3] = labels_tmp[3], labels_tmp[1]\n",
    "                labels_tmp[4], labels_tmp[8] = 96-labels_tmp[8], 96-labels_tmp[4]\n",
    "                labels_tmp[5], labels_tmp[9] = labels_tmp[9], labels_tmp[5]\n",
    "                labels_tmp[6], labels_tmp[10] = 96-labels_tmp[10], 96-labels_tmp[6]\n",
    "                labels_tmp[7], labels_tmp[11] = labels_tmp[11], labels_tmp[7]\n",
    "                labels_tmp[12], labels_tmp[16] = 96-labels_tmp[16], 96-labels_tmp[12]\n",
    "                labels_tmp[13], labels_tmp[17] = labels_tmp[17], labels_tmp[13]\n",
    "                labels_tmp[14], labels_tmp[18] = 96-labels_tmp[18], 96-labels_tmp[14]\n",
    "                labels_tmp[15], labels_tmp[19] = labels_tmp[19], labels_tmp[15]\n",
    "                labels_tmp[22], labels_tmp[24] = 96-labels_tmp[24], 96-labels_tmp[22]\n",
    "                labels_tmp[23], labels_tmp[25] = labels_tmp[25], labels_tmp[23]\n",
    "\n",
    "                # Nose tip \n",
    "                labels_tmp[20], labels_tmp[21] = 96-labels_tmp[20], labels_tmp[21]\n",
    "\n",
    "                # Mouth bottom\n",
    "                labels_tmp[26], labels_tmp[27] = 96-labels_tmp[26], labels_tmp[27]\n",
    "\n",
    "                # Mouth top\n",
    "                labels_tmp[28], labels_tmp[29] = 96-labels_tmp[28], labels_tmp[29]\n",
    "            elif label_count==8:\n",
    "                labels_tmp[0], labels_tmp[2] = 96-labels_tmp[2], 96-labels_tmp[0]\n",
    "                labels_tmp[1], labels_tmp[3] = labels_tmp[3], labels_tmp[1]\n",
    "                labels_tmp[4], labels_tmp[5] = 96-labels_tmp[4], labels_tmp[5]\n",
    "                labels_tmp[6], labels_tmp[7] = 96-labels_tmp[6], labels_tmp[7]\n",
    "            \n",
    "            # for every picture/frame, save all the y coordinate changes\n",
    "            train_labels_y_reflection[i] = np.array(labels_tmp)\n",
    "\n",
    "\n",
    "        # For debugging only. \n",
    "        if labels==True and logging==True and (i==300 or i==500 or i==700 or i==1000):\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.imshow(np.reshape(train_data_y_reflection[i],(96,96)), cmap = cm.gray)\n",
    "            \n",
    "            for x, y in np.reshape(train_labels_y_reflection[i], (len(train_labels_y_reflection[i])/2, 2)):\n",
    "                plt.plot(x, y, 'b.')\n",
    "                plt.title(\"Reflection around  the Y axis: Reflected frame\")\n",
    "                plt.ylim([96,0])\n",
    "                plt.xlim([0,96])\n",
    "\n",
    "    # return the reflected frames\n",
    "    return train_data_y_reflection, train_labels_y_reflection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Reflect frames around y axis - START\")\n",
    "reflected_data_yaxis, reflected_labels_yaxis = reflect_all_by_y_axis(labels=True, label_count=30, logging=True)\n",
    "\n",
    "np.random.seed(0)\n",
    "sample = np.random.rand(5) * len(train_data)\n",
    "#sample=[200]\n",
    "for i in sample:\n",
    "    before = train_data[i]\n",
    "    after = reflected_data_yaxis[i]\n",
    "    #print(after)\n",
    "    #compare_histograms(before, after)\n",
    "    compare_images(before, train_labels[i], after, (reflected_labels_yaxis[i]-48)/48)\n",
    "    \n",
    "    \n",
    "print(\"Reflect frames around y axis - END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First get the y axis reflection\n",
    "reflected_labels_yaxis = (reflected_labels_yaxis -48)/48\n",
    "augmented_data_reflect_y=np.concatenate((train_data, reflected_data_yaxis), axis=0)\n",
    "augmented_labels_reflect_y=np.concatenate((train_labels, reflected_labels_yaxis), axis=0)\n",
    "\n",
    "# SET THE augmented_data and augment_labels values here. \n",
    "augmented_data_1=augmented_data_reflect_y.copy()\n",
    "augmented_labels_1=augmented_labels_reflect_y.copy()\n",
    "\n",
    "# Now rotate the data to generate the 3rd block of train data\n",
    "rotated_data_tmp, rotated_labels_tmp = \\\n",
    "                sample_rotate_all(train_data=augmented_data_1, train_labels=augmented_labels_1, label_count=30)\n",
    "\n",
    "augmented_data = np.vstack((augmented_data_1, rotated_data_tmp))\n",
    "#print(augmented_data.shape)\n",
    "\n",
    "# Normalize the labels\n",
    "rotated_labels_tmp = (rotated_labels_tmp - 48)/48\n",
    "\n",
    "# Create the augmented labels matrix\n",
    "augmented_labels = np.vstack((augmented_labels_1, rotated_labels_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_sample(x, y, axis):\n",
    "    img = x.reshape(96, 96)\n",
    "    axis.imshow(img, cmap='gray')\n",
    "    axis.scatter(y[0::2] * 48 + 48, y[1::2] * 48 + 48, marker='x', s=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#in order to change the learning rates and momemtum, we need to make it a shared variable in theano.\n",
    "#http://lasagne.readthedocs.io/en/latest/user/layers.html\n",
    "import theano\n",
    "\n",
    "def float32(var):\n",
    "    return np.cast['float32'](var)\n",
    "\n",
    "#This adjust variable call was modified from Danile Nouri's tutorial.\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            #create evenly spaced values based on the starting and stopping values, divided evenly by the num of epochs\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING -AUGMENTED DATA - BASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretching, Shifting, Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(train_data)\n",
    "from datetime import datetime\n",
    "print(str(datetime.now()))\n",
    "print(\"Starting the generation of composite data\")\n",
    "transformed_data_1 = stretch_histogram_all(augmented_data)\n",
    "#transformed_data = stretch_histogram_all(train_data)\n",
    "# print(transformed_data.shape)\n",
    "# print(transformed_data)\n",
    "print(\"Finished stretching. Starting left shift\")\n",
    "print(str(datetime.now()))\n",
    "transformed_data_2 = shift_histogram_left_all(transformed_data_1)\n",
    "# print(transformed_data.shape)\n",
    "# print(transformed_data)\n",
    "print(\"Finished shifting. Starting blur\")\n",
    "print(str(datetime.now()))\n",
    "transformed_data_3 = apply_blur_all(transformed_data_2)\n",
    "# print(transformed_data.shape)\n",
    "# print(transformed_data)\n",
    "print(\"Finished Blur\")\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(augmented_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Darkening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(str(datetime.now()))\n",
    "print(\"Start darkening eyes\")\n",
    "transformed_data_4 = darken_eyes_all(images=transformed_data_3)\n",
    "# print(transformed_data.shape)\n",
    "# print(transformed_data)\n",
    "print(\"Finished darkening eyes\")\n",
    "print(transformed_data_4.shape)\n",
    "print(augmented_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create transformed data for feeding into CNET5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_data_2d = transformed_data_4.reshape(len(transformed_data_4), 1, 96, 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNET5 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnet5 = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('hidden5', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    \n",
    "    input_shape=(None, 1, 96, 96),\n",
    "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2),\n",
    "    hidden4_num_units=500, hidden5_num_units=500,\n",
    "    output_num_units=8, output_nonlinearity=None,\n",
    "\n",
    "    update_learning_rate=theano.shared(np.float32(0.03)),\n",
    "    update_momentum=theano.shared(np.float32(0.9)),\n",
    "\n",
    "    on_epoch_finished=[\n",
    "        AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
    "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "        ],\n",
    "    \n",
    "    regression=True,\n",
    "    max_epochs=100,\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the CNET5 Model - Using Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnet5.fit(transformed_data_2d.astype(np.float32), augmented_labels.astype(np.float32))\n",
    "\n",
    "graph_results(cnet5)\n",
    "\n",
    "with open('cnet5_enhanced_12312016_v3.pickle', 'wb') as f:\n",
    "    pickle.dump(cnet5, f, -1)\n",
    "pickle.dump(cnet5, open(\"cnet5_enhanced_12312016_v2.pickle\", 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "augmented_data_final_8_2d = augmented_data_final_8.reshape(len(augmented_data_final_8), 1, 96, 96)\n",
    "cnet5.fit(augmented_data_final_8_2d.astype(np.float32), augmented_labels_final_8.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoints detection in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transforming test dataset by applying stretch/shift histogram\n",
    "# and gaussian blur.\n",
    "test_transformed= np.array(map(stretch_histogram, test_data))\n",
    "test_transformed= np.array(map(shift_histogram, test_transformed))\n",
    "test_transformed= np.array(map(apply_blur, test_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_transformed=augmented_data.astype(np.float32)\n",
    "from random import randint\n",
    "\n",
    "test_data_2d = test_transformed.reshape(len(test_transformed), 1, 96, 96)\n",
    "test_pred = cnet5.predict(test_data_2d) \n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "fig.subplots_adjust(\n",
    "    left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i in range(16):\n",
    "    test_idx = randint(0, len(test_data))\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    plot_sample(test_data[test_idx], test_pred[test_idx], ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future: Median Angle Minimization (MAM) Transformation\n",
    "\n",
    "Centering of a given face with respect to face inherent features is something that our team will study next. By overlaying two independently swiveling orientation triangles on the face and by using medians as the features and by using a transformation to reduce the angle betwen the medians to 0, we hope to better center the face so that prediction algorithmns have a higher degree of accuracy. Figue below captures the basic scheme of Centroids and inter-centoid Angle Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"MAX.png\",width=500,height=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future: Critical Pixel Enhancement (CPE) Transformation + MAM Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A combination of face centering, along with pixel enhancement, at the 6 vertices of the 2 critical orientation \n",
    "triangles is also in the future. By enhancing pixel intensity in 5% delta (pixel radius) circles, we hope to highlight\n",
    "the vertices and hence facilitate better centering and recognition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PET.png\",width=500,height=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "# KAGGLE  DATA: SPLIT DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FTRAIN = '../data/training.csv'\n",
    "FTEST = '../data/test.csv'\n",
    "FLOOKUP ='../data/IdLookupTable.csv'\n",
    "\n",
    "\n",
    "def load(test=False, cols=None):\n",
    "    \"\"\"Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n",
    "    Pass a list of *cols* if you're only interested in a subset of the\n",
    "    target columns.\n",
    "    \"\"\"\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = read_csv(os.path.expanduser(fname))  # load pandas dataframe\n",
    "\n",
    "    # The Image column has pixel values separated by space; convert\n",
    "    # the values to numpy arrays:\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "    if cols:  # get a subset of columns\n",
    "        df = df[list(cols) + ['Image']]\n",
    "\n",
    "    print(df.count())  # prints the number of values for each column\n",
    "#     df = df.dropna()  # drop all rows that have missing values in them\n",
    "\n",
    "    X = np.vstack(df['Image'].values) / 255.  # scale pixel values to [0, 1]\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    if not test:  # only FTRAIN has any target columns\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  # scale target coordinates to [-1, 1]\n",
    "#         X, y = shuffle(X, y, random_state=42)  # shuffle train data\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = load()\n",
    "print(\"X.shape == {}; X.min == {:.3f}; X.max == {:.3f}\".format(\n",
    "    X.shape, X.min(), X.max()))\n",
    "print(\"y.shape == {}; y.min == {:.3f}; y.max == {:.3f}\".format(\n",
    "    y.shape, y.min(), y.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_count_na = np.sum(np.isnan(y),1)\n",
    "plt.plot(y_count_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_ds_2 = y_count_na.tolist().index(22)\n",
    "\n",
    "img_ds_30 = X[:idx_ds_2]\n",
    "img_ds_8 = X[idx_ds_2:]\n",
    "\n",
    "train_ds_30 = y[:idx_ds_2]\n",
    "train_ds_8 = y[idx_ds_2:]\n",
    "\n",
    "print(img_ds_30.shape, img_ds_8.shape)\n",
    "print(train_ds_30.shape, train_ds_8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keypoints = ['left_eye_center_x','left_eye_center_y','right_eye_center_x','right_eye_center_y','left_eye_inner_corner_x', \\\n",
    "             'left_eye_inner_corner_y','left_eye_outer_corner_x','left_eye_outer_corner_y','right_eye_inner_corner_x', \\\n",
    "             'right_eye_inner_corner_y','right_eye_outer_corner_x','right_eye_outer_corner_y','left_eyebrow_inner_end_x', \\\n",
    "             'left_eyebrow_inner_end_y','left_eyebrow_outer_end_x','left_eyebrow_outer_end_y','right_eyebrow_inner_end_x', \\\n",
    "             'right_eyebrow_inner_end_y','right_eyebrow_outer_end_x','right_eyebrow_outer_end_y','nose_tip_x','nose_tip_y', \\\n",
    "             'mouth_left_corner_x','mouth_left_corner_y','mouth_right_corner_x','mouth_right_corner_y', \\\n",
    "             'mouth_center_top_lip_x','mouth_center_top_lip_y','mouth_center_bottom_lip_x','mouth_center_bottom_lip_y']\n",
    "\n",
    "keypoints_ds_8 = [0,1,2,3,20,21,28,29]\n",
    "\n",
    "\n",
    "train_ds_8_sub = train_ds_8[:,keypoints_ds_8]\n",
    "print(train_ds_8_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_ds_8[0])\n",
    "print(train_ds_8_sub[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_8_nona_idx = np.sum(np.isnan(train_ds_8_sub),1) == 0\n",
    "train_30_nona_idx = np.sum(np.isnan(train_ds_30),1) == 0\n",
    "\n",
    "img_8_nona = img_ds_8[train_8_nona_idx]\n",
    "img_30_nona = img_ds_30[train_30_nona_idx]\n",
    "\n",
    "train_8_nona = train_ds_8_sub[train_8_nona_idx]\n",
    "train_30_nona = train_ds_30[train_30_nona_idx]\n",
    "\n",
    "print(img_8_nona.shape, img_30_nona.shape)\n",
    "print(train_8_nona.shape, train_30_nona.shape)\n",
    "\n",
    "plt.plot(train_8_nona_idx)\n",
    "plt.plot(train_30_nona_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def float32(var):\n",
    "    return np.cast['float32'](var)\n",
    "\n",
    "\n",
    "#This adjust variable call was modified from Danile Nouri's tutorial.\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            #create evenly spaced values based on the starting and stopping values, divided evenly by the num of epochs\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "        \n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience=100):\n",
    "        self.patience = patience\n",
    "        self.best_valid = np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        current_valid = train_history[-1]['valid_loss']\n",
    "        current_epoch = train_history[-1]['epoch']\n",
    "        if current_valid < self.best_valid:\n",
    "            self.best_valid = current_valid\n",
    "            self.best_valid_epoch = current_epoch\n",
    "            self.best_weights = nn.get_all_params_values()\n",
    "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
    "            print(\"Early stopping.\")\n",
    "            print(\"Best valid loss was {:.6f} at epoch {}.\".format(\n",
    "                self.best_valid, self.best_valid_epoch))\n",
    "            nn.load_params_from(self.best_weights)\n",
    "            raise StopIteration()\n",
    "\n",
    "def graph_results(net):\n",
    "    train_loss = np.array([i[\"train_loss\"] for i in net.train_history_])\n",
    "    valid_loss = np.array([i[\"valid_loss\"] for i in net.train_history_])\n",
    "    plt.plot(train_loss, linewidth=3, label=\"train\")\n",
    "    plt.plot(valid_loss, linewidth=3, label=\"valid\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.ylim(1e-4, 1e-2)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_8_d = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('dropout1', layers.DropoutLayer),  # !\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('dropout2', layers.DropoutLayer),  # !\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('dropout3', layers.DropoutLayer),  # !\n",
    "        ('conv4', layers.Conv2DLayer),\n",
    "        ('pool4', layers.MaxPool2DLayer),\n",
    "        ('dropout4', layers.DropoutLayer),  # !\n",
    "        ('hidden5', layers.DenseLayer),\n",
    "        ('hidden6', layers.DenseLayer),\n",
    "        ('hidden7', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 1, 96, 96),\n",
    "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "    dropout1_p=0.1,  # !\n",
    "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "    dropout2_p=0.2,  # !\n",
    "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2),\n",
    "    dropout3_p=0.3,  # !\n",
    "    conv4_num_filters=256, conv4_filter_size=(2, 2), pool4_pool_size=(1, 1),\n",
    "    dropout4_p=0.4,  # !\n",
    "    hidden5_num_units=500,\n",
    "    hidden6_num_units=500,\n",
    "    hidden7_num_units=500,\n",
    "    output_num_units=8, output_nonlinearity=None,\n",
    "\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "\n",
    "    regression=True,\n",
    "#     batch_iterator_train=FlipBatchIterator(batch_size=128),\n",
    "    on_epoch_finished=[\n",
    "        AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
    "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "        EarlyStopping(patience=200),\n",
    "        ],\n",
    "    max_epochs=1000,\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate the images that have only 8 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Reflect frames around y axis - START\")\n",
    "reflected_data_8, reflected_labels_8 = \\\n",
    "        reflect_all_by_y_axis(train_data=img_8_nona, train_labels=train_8_nona, \\\n",
    "                              labels=True, label_count=8, logging=True)\n",
    "\n",
    "print(reflected_data_8.shape)\n",
    "print(reflected_labels_8.shape)\n",
    "\n",
    "# First get the y axis reflection and append it to train_data\n",
    "reflected_labels_8=(reflected_labels_8 - 48)/48\n",
    "augmented_data_8=np.concatenate((img_8_nona, reflected_data_8), axis=0)\n",
    "augmented_labels_8=np.concatenate((train_8_nona, reflected_labels_8), axis=0)\n",
    "\n",
    "print(augmented_data_8.shape)\n",
    "print(augmented_labels_8.shape)\n",
    "\n",
    "# Now rotate the data to generate the 3rd block of train data\n",
    "rotated_data_tmp, rotated_labels_tmp = \\\n",
    "                sample_rotate_all(train_data=augmented_data_8, train_labels=augmented_labels_8, label_count=8)\n",
    "\n",
    "augmented_data_final_8 = np.vstack((augmented_data_8, rotated_data_tmp))\n",
    "rotated_labels_tmp = (rotated_labels_tmp - 48)/48\n",
    "augmented_labels_final_8 = np.vstack((augmented_labels_8, rotated_labels_tmp))\n",
    "\n",
    "print(augmented_data_final_8.shape)\n",
    "print(augmented_labels_final_8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "samples = np.floor(np.random.rand(5) * len(reflected_data_8))\n",
    "for sample in samples:\n",
    "    plt.imshow(np.reshape(reflected_data_8[sample].flatten(),(96,96)), cmap = cm.gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "augmented_data_final_8_2d = augmented_data_final_8.reshape(len(augmented_data_final_8), 1, 96, 96)\n",
    "net_8_d.fit(augmented_data_final_8_2d.astype(np.float32), augmented_labels_final_8.astype(np.float32))\n",
    "\n",
    "graph_results(net_8_d)\n",
    "\n",
    "with open('net_8_d.pickle', 'wb') as f:\n",
    "    pickle.dump(net_8_d, f, -1)\n",
    "    \n",
    "graph_results(net_8_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now work with images that have 30 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_30_d = NeuralNet(\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('dropout1', layers.DropoutLayer),  # !\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('dropout2', layers.DropoutLayer),  # !\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('pool3', layers.MaxPool2DLayer),\n",
    "        ('dropout3', layers.DropoutLayer),  # !\n",
    "        ('conv4', layers.Conv2DLayer),\n",
    "        ('pool4', layers.MaxPool2DLayer),\n",
    "        ('dropout4', layers.DropoutLayer),  # !\n",
    "        ('hidden5', layers.DenseLayer),\n",
    "        ('hidden6', layers.DenseLayer),\n",
    "        ('hidden7', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 1, 96, 96),\n",
    "    conv1_num_filters=32, conv1_filter_size=(3, 3), pool1_pool_size=(2, 2),\n",
    "    dropout1_p=0.1,  # !\n",
    "    conv2_num_filters=64, conv2_filter_size=(2, 2), pool2_pool_size=(2, 2),\n",
    "    dropout2_p=0.2,  # !\n",
    "    conv3_num_filters=128, conv3_filter_size=(2, 2), pool3_pool_size=(2, 2),\n",
    "    dropout3_p=0.3,  # !\n",
    "    conv4_num_filters=256, conv4_filter_size=(2, 2), pool4_pool_size=(1, 1),\n",
    "    dropout4_p=0.4,  # !\n",
    "    hidden5_num_units=500,\n",
    "    hidden6_num_units=500,\n",
    "    hidden7_num_units=500,\n",
    "    output_num_units=30, output_nonlinearity=None,\n",
    "\n",
    "    update_learning_rate=theano.shared(float32(0.03)),\n",
    "    update_momentum=theano.shared(float32(0.9)),\n",
    "\n",
    "    regression=True,\n",
    "#     batch_iterator_train=FlipBatchIterator(batch_size=128),\n",
    "    on_epoch_finished=[\n",
    "        AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
    "        AdjustVariable('update_momentum', start=0.9, stop=0.999),\n",
    "        EarlyStopping(patience=200),\n",
    "        ],\n",
    "    max_epochs=1000,\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate the images that have 30 attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Reflect frames around y axis - START\")\n",
    "reflected_data_30, reflected_labels_30 = \\\n",
    "        reflect_all_by_y_axis(train_data=img_30_nona, train_labels=train_30_nona, \\\n",
    "                              labels=True, label_count=30, logging=True)\n",
    "\n",
    "print(reflected_data_30.shape)\n",
    "print(reflected_labels_30.shape)\n",
    "\n",
    "# First get the y axis reflection and append it to train_data\n",
    "reflected_labels_30=(reflected_labels_30 - 48)/48\n",
    "augmented_data_30=np.concatenate((img_30_nona, reflected_data_30), axis=0)\n",
    "augmented_labels_30=np.concatenate((train_30_nona, reflected_labels_30), axis=0)\n",
    "\n",
    "print(augmented_data_30.shape)\n",
    "print(augmented_labels_30.shape)\n",
    "\n",
    "# Now rotate the data to generate the 3rd block of train data\n",
    "rotated_data_tmp, rotated_labels_tmp = \\\n",
    "                sample_rotate_all(train_data=augmented_data_30, train_labels=augmented_labels_30, label_count=30)\n",
    "\n",
    "augmented_data_final_30 = np.vstack((augmented_data_30, rotated_data_tmp))\n",
    "rotated_labels_tmp = (rotated_labels_tmp - 48)/48\n",
    "augmented_labels_final_30 = np.vstack((augmented_labels_30, rotated_labels_tmp))\n",
    "\n",
    "print(augmented_data_final_30.shape)\n",
    "print(augmented_labels_final_30.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_30_nona_2d = augmented_data_final_30.reshape(len(augmented_data_final_30), 1, 96, 96)\n",
    "net_30_d.fit(img_30_nona_2d, augmented_labels_final_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('net_30_d.pickle', 'wb') as f:\n",
    "    pickle.dump(net_30_d, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLOOKUP = '../data/IdLookupTable.csv'\n",
    "submissionImages = read_csv(os.path.expanduser(FLOOKUP))\n",
    "subKeypoints = submissionImages.groupby(['ImageId']).size()\n",
    "idx_sub_ds_8 = subKeypoints.tolist().index(8)\n",
    "print idx_sub_ds_8\n",
    "plt.plot(subKeypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print submissionImages[:5]\n",
    "print submissionImages[submissionImages['ImageId'] == 592]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prep test data\n",
    "test_img, foo = load(test=True) \n",
    "test_img_30 = test_img[:idx_sub_ds_8]\n",
    "test_img_8 = test_img[idx_sub_ds_8:]\n",
    "\n",
    "print test_img_30.shape, test_img_8.shape\n",
    "\n",
    "test_img_30_2d = test_img_30.reshape(len(test_img_30), 1, 96, 96)\n",
    "test_img_8_2d = test_img_8.reshape(len(test_img_8), 1, 96, 96)\n",
    "\n",
    "print test_img_30_2d.shape, test_img_8_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "test_pred_30 = net_30_d.predict(test_img_30_2d)\n",
    "test_pred_8 = net_8_d.predict(test_img_8_2d)\n",
    "\n",
    "print test_pred_30.shape, test_pred_8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sample(x, y, axis):\n",
    "    img = x.reshape(96, 96)\n",
    "    axis.imshow(img, cmap='gray')\n",
    "    axis.scatter(y[0::2] * 48 + 48, y[1::2] * 48 + 48, marker='x', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "fig.subplots_adjust(\n",
    "    left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i in range(16):\n",
    "    test_idx = randint(0, len(test_pred_30))\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    plot_sample(test_img_30[test_idx], test_pred_30[test_idx], ax)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "fig.subplots_adjust(\n",
    "    left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i in range(16):\n",
    "    test_idx = randint(0, len(test_pred_8))\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    plot_sample(test_img_8[test_idx], test_pred_8[test_idx], ax)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_30_fmt = test_pred_30 * 48 + 48\n",
    "test_pred_8_fmt = test_pred_8 * 48 + 48\n",
    "\n",
    "# Generating submissions\n",
    "arr = [['RowId','ImageId','FeatureName','Location']]\n",
    "rowIdx = 0\n",
    "\n",
    "# Parsing first dataset\n",
    "for i in range(0, test_pred_30.shape[0]):\n",
    "    for j in range(0, 30):\n",
    "        rowIdx += 1\n",
    "        arr.append([rowIdx, i + 1, keypoints[j], test_pred_30_fmt[i,j]])\n",
    "        \n",
    "# Parsing second dataset\n",
    "for i in range(0, test_pred_8.shape[0]):\n",
    "    for idx, j in enumerate(keypoints_ds_8):\n",
    "        rowIdx += 1\n",
    "        # Note ImageId starts from 592 for ds 2\n",
    "        arr.append([rowIdx, 591 + i + 1, keypoints[j], test_pred_8_fmt[i,idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(arr), len(arr[0])\n",
    "print submissionImages[:5]\n",
    "print arr[:5]\n",
    "print submissionImages[-5:]\n",
    "print arr[-5:]\n",
    "print pd.DataFrame(arr[1:], columns=arr[0])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_df = pd.DataFrame(arr[1:], columns=arr[0])\n",
    "submission = pd.merge(left = submissionImages, right=arr_df, how=\"left\", \\\n",
    "                      left_on=[\"ImageId\",\"FeatureName\"], right_on=[\"ImageId\",\"FeatureName\"]) \n",
    "print submission[:5]\n",
    "print submission[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissionSub = submission[[0,5]]\n",
    "submissionSub.columns = ['RowId', 'Location']\n",
    "submissionSub.to_csv('keypoint_submission_v0.3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
